{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af41daf1-275b-4dfe-8933-519938066ee5",
   "metadata": {},
   "source": [
    "# Part 2: Further Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1d5114-2fcf-4b78-bdc7-cae799828d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d625fa-5c4b-4a04-842c-ffc4adf062dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./reduced_by_half_recipe_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b60e411-eb4d-45bb-ab0e-cb09a8b8aca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1a0c36-18cc-4a29-85ef-d3b09813f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['index', 'Unnamed: 0'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155d22d6-1fe8-421e-8d16-d65caaa42942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1116c37f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eac9148-04cc-4f76-a43d-5946ae620767",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brown',\n",
       " 'sour',\n",
       " 'frozen',\n",
       " 'garlic',\n",
       " 'powdered',\n",
       " 'extra',\n",
       " 'lean',\n",
       " 'green',\n",
       " 'whole',\n",
       " 'dark',\n",
       " 'sweet',\n",
       " 'vegetable',\n",
       " 'italian',\n",
       " 'black',\n",
       " 'yellow',\n",
       " 'parmesan',\n",
       " 'warm',\n",
       " 'multi',\n",
       " '-',\n",
       " 'colored',\n",
       " 'mixed',\n",
       " 'salad',\n",
       " 'dry',\n",
       " 'crumb',\n",
       " 'coconut',\n",
       " 'cold',\n",
       " 'thin',\n",
       " 'olive',\n",
       " 'walnut',\n",
       " 'junior',\n",
       " 'spanish',\n",
       " 'orange',\n",
       " 'moist',\n",
       " 'instant',\n",
       " 'american',\n",
       " 'triple',\n",
       " 'chinese',\n",
       " 'purple',\n",
       " 'chili',\n",
       " 'unflavored',\n",
       " 'rosemary',\n",
       " 'wild',\n",
       " 'lasagne',\n",
       " 'hot',\n",
       " 'light',\n",
       " 'plain',\n",
       " 'heavy',\n",
       " 'mayonnaise',\n",
       " 'unsalted',\n",
       " 'canadian',\n",
       " 'swiss',\n",
       " 'crisp',\n",
       " 'sesame',\n",
       " 'dripping',\n",
       " 'regular',\n",
       " 'commerical',\n",
       " 'golden',\n",
       " 'currant',\n",
       " 'oatmeal',\n",
       " 'chunky',\n",
       " 'irish',\n",
       " 'pink',\n",
       " 'breadcrumb',\n",
       " 'faux',\n",
       " 'crabmeat',\n",
       " 'ready',\n",
       " 'crab',\n",
       " 'chive',\n",
       " 'baked',\n",
       " 'stew',\n",
       " 'cheez',\n",
       " 'crunchy',\n",
       " 'pet',\n",
       " 'coarse',\n",
       " 'raw',\n",
       " 'northern',\n",
       " 'solid',\n",
       " 'pumpkin',\n",
       " 'borden',\n",
       " 'liquid',\n",
       " 'delicious',\n",
       " 'stale',\n",
       " 'patty',\n",
       " 'cinnamon',\n",
       " 'blanched',\n",
       " 'hearty',\n",
       " 'wide',\n",
       " 'clear',\n",
       " 'firm',\n",
       " 'nondairy',\n",
       " 'caraway',\n",
       " 'lite',\n",
       " 'eyed',\n",
       " 'accent',\n",
       " 'top',\n",
       " 'active',\n",
       " 'bitter',\n",
       " 'poppy',\n",
       " 'eastern',\n",
       " 'provolone',\n",
       " 'unbaked',\n",
       " 'feta',\n",
       " 'phyllo',\n",
       " 'gummy',\n",
       " 'popcorn',\n",
       " 'smooth',\n",
       " 'generous',\n",
       " 'flaky',\n",
       " 'oreo',\n",
       " 'seasoned',\n",
       " 'linguine',\n",
       " 'ground',\n",
       " 'spiral',\n",
       " 'pecan',\n",
       " 'italian-',\n",
       " 'basic',\n",
       " 'crushed',\n",
       " 'fine',\n",
       " 'puree']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjective\n",
    "# Looking at adjectives we might not need\n",
    "adj = []\n",
    "for token in df['raw_ingredients'][:1000]:\n",
    "    doc = nlp(token)\n",
    "    for i in doc:\n",
    "        if (i.pos_=='ADJ'): \n",
    "            adj.append(i)\n",
    "        \n",
    "#Removing the duplicated words from the list        \n",
    "adj = [i.text for i in adj]\n",
    "\n",
    "result_adj = []\n",
    "for item in adj:\n",
    "    if item not in result_adj:\n",
    "        result_adj.append(item)\n",
    "result_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e896243-8b26-4252-950f-b1dc4734b7b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baking',\n",
       " 'condensed',\n",
       " 'pitted',\n",
       " 'cleaned',\n",
       " 'pear',\n",
       " 'curry',\n",
       " 'drop',\n",
       " 'margarine',\n",
       " 'corned',\n",
       " 'granulated',\n",
       " 'whipping',\n",
       " 'frozen',\n",
       " 'dried',\n",
       " 'steak',\n",
       " 'bite',\n",
       " 'artichoke',\n",
       " 'coloring',\n",
       " 'flavored',\n",
       " 'slivered',\n",
       " 'topping',\n",
       " 'flaked',\n",
       " 'candied',\n",
       " 'floured',\n",
       " 'salad',\n",
       " 'paraffin',\n",
       " 'whipped',\n",
       " 'romaine',\n",
       " 'crushed',\n",
       " 'roll',\n",
       " 'butterscotch',\n",
       " 'sausage',\n",
       " 'molasses',\n",
       " 'buttered',\n",
       " 'pickling',\n",
       " 'great',\n",
       " 'flavoring',\n",
       " 'shell',\n",
       " 'chop',\n",
       " 'dressing',\n",
       " 'stove',\n",
       " 'stuffing',\n",
       " 'cooking',\n",
       " 'toasted',\n",
       " 'powdered',\n",
       " 'rolled',\n",
       " 'quartered',\n",
       " 'orange',\n",
       " 'lettuce',\n",
       " 'peppercorn',\n",
       " 'concentrate',\n",
       " 'sparkling',\n",
       " 'seasoned',\n",
       " 'bisquick',\n",
       " 'creamed',\n",
       " 'playing',\n",
       " 'kiss',\n",
       " 'reduced',\n",
       " 'recipe',\n",
       " 'squeezed']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verbs\n",
    "# Looking at verbs we might not need\n",
    "verbs = []\n",
    "for token in df['raw_ingredients'][:1000]:\n",
    "    doc = nlp(token)\n",
    "    for i in doc:\n",
    "        if (i.pos_=='VERB'): \n",
    "            verbs.append(i)\n",
    "        \n",
    "#Removing the duplicated words from the list        \n",
    "verbs = [i.text for i in verbs]\n",
    "\n",
    "result_verbs = []\n",
    "for item in verbs:\n",
    "    if item not in result_verbs:\n",
    "        result_verbs.append(item)\n",
    "result_verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5f4cb-50e3-4f4f-a424-883c6acfda58",
   "metadata": {},
   "source": [
    "##### Annotation\n",
    "Using spaCy I was able to identify verbs and adjectives still present in the ingredient column that were unnecessary. Once the verbs and adjective were identified they were added to a list containing only their unique values. Once in that list, I went on and manually explored how that word was used in the ingredient list. If I deemed that word unnecessary I added it to the second word_remover list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e5fa834-1d3b-4812-b1a3-966368e5e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_remover = ['freshly','unsliced','peel','cooking','melt','broiler-fryers','unprocessed',\n",
    "                'confectionery',\"'s\",'homestyle','instant','packet','squeezed','frozen','extra','whole',\n",
    "                'warm', 'cold','thin','junior baby', 'baby', 'moist', 'spanish', 'american', 'chinese','regular',\n",
    "                'light', 'canadian','crisp','commercial', 'ready', 'delicious','stale', 'wide','clear',\n",
    "                 'firm','liter', 'unbaked', 'smooth', 'generous','cleaned','granulated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5187259f-ac6f-4334-bd26-70762bef4890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-3e328cab47f7>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['raw_ingredients'] = df['raw_ingredients'].str.replace(pat, '')\n"
     ]
    }
   ],
   "source": [
    "pat = r'\\b(?:{})\\b'.format('|'.join(word_remover))\n",
    "df['raw_ingredients'] = df['raw_ingredients'].str.replace(pat, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af333a54-6f64-49e5-b476-2494483c632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('recipe_cleaned_spacy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212297d3-f7da-406a-b19b-91d8394bf150",
   "metadata": {},
   "source": [
    "##### Annotation:\n",
    "The cleaned data set was exported and EDA was conducted. While conducting EDA I found out that the ingredient count was not distributed and that certain recipes exceeded the 20 ingredient mark. I decided to drop all recipes that exceeded 20 ingredients and exported the data set into its final csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a66c7e10-1fbb-46e7-ba9d-ba61b2aae90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredient_count'] = [len(i.split(', ')) for i in df['raw_ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "283b6ad6-60c1-4755-a122-8e53f7b41694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ingredient_count']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a2c33d7-cc68-410a-9bda-fb6bdb0832d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['ingredient_count'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39890608-d5ae-47a2-b0e8-9eb5a15fb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6ae53cf-ec4b-48ef-bdc9-7d8039b7f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('recipe_cleaned_spacy2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
